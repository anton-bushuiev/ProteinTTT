{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "from proteinttt.models.esm2 import ESM2TTT, DEFAULT_ESM2_35M_TTT_CFG\n",
    "from proteinttt.models.esmfold import ESMFoldTTT, DEFAULT_ESMFOLD_TTT_CFG\n",
    "from proteinttt.base import TTTConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESM2\n",
    "\n",
    "Adaptation of an official [ESM2 example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-25 19:15:37,554 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 0.00000\n",
      "2025-10-25 19:15:37,985 | INFO | step: 1, accumulated_step: 16, loss: 0.75260, perplexity: None, ttt_step_time: 0.43038, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:38,411 | INFO | step: 2, accumulated_step: 32, loss: 0.73837, perplexity: None, ttt_step_time: 0.42509, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:38,835 | INFO | step: 3, accumulated_step: 48, loss: 0.68426, perplexity: None, ttt_step_time: 0.42412, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:39,261 | INFO | step: 4, accumulated_step: 64, loss: 0.69365, perplexity: None, ttt_step_time: 0.42529, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:39,688 | INFO | step: 5, accumulated_step: 80, loss: 0.67766, perplexity: None, ttt_step_time: 0.42601, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:40,115 | INFO | step: 6, accumulated_step: 96, loss: 0.70075, perplexity: None, ttt_step_time: 0.42676, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:40,541 | INFO | step: 7, accumulated_step: 112, loss: 0.65884, perplexity: None, ttt_step_time: 0.42513, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:40,968 | INFO | step: 8, accumulated_step: 128, loss: 0.66001, perplexity: None, ttt_step_time: 0.42724, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:41,396 | INFO | step: 9, accumulated_step: 144, loss: 0.64459, perplexity: None, ttt_step_time: 0.42721, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:41,822 | INFO | step: 10, accumulated_step: 160, loss: 0.64300, perplexity: None, ttt_step_time: 0.42573, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:42,249 | INFO | step: 11, accumulated_step: 176, loss: 0.63965, perplexity: None, ttt_step_time: 0.42585, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:42,676 | INFO | step: 12, accumulated_step: 192, loss: 0.58372, perplexity: None, ttt_step_time: 0.42651, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:43,103 | INFO | step: 13, accumulated_step: 208, loss: 0.61558, perplexity: None, ttt_step_time: 0.42711, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:43,530 | INFO | step: 14, accumulated_step: 224, loss: 0.61332, perplexity: None, ttt_step_time: 0.42648, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:43,958 | INFO | step: 15, accumulated_step: 240, loss: 0.60931, perplexity: None, ttt_step_time: 0.42689, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:44,384 | INFO | step: 16, accumulated_step: 256, loss: 0.63115, perplexity: None, ttt_step_time: 0.42525, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:44,810 | INFO | step: 17, accumulated_step: 272, loss: 0.56141, perplexity: None, ttt_step_time: 0.42537, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:45,237 | INFO | step: 18, accumulated_step: 288, loss: 0.56737, perplexity: None, ttt_step_time: 0.42648, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:45,663 | INFO | step: 19, accumulated_step: 304, loss: 0.59121, perplexity: None, ttt_step_time: 0.42564, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:46,090 | INFO | step: 20, accumulated_step: 320, loss: 0.54132, perplexity: None, ttt_step_time: 0.42681, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:46,518 | INFO | step: 21, accumulated_step: 336, loss: 0.52530, perplexity: None, ttt_step_time: 0.42737, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:46,944 | INFO | step: 22, accumulated_step: 352, loss: 0.56913, perplexity: None, ttt_step_time: 0.42530, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:47,370 | INFO | step: 23, accumulated_step: 368, loss: 0.49984, perplexity: None, ttt_step_time: 0.42597, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:47,797 | INFO | step: 24, accumulated_step: 384, loss: 0.52193, perplexity: None, ttt_step_time: 0.42640, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:48,224 | INFO | step: 25, accumulated_step: 400, loss: 0.50582, perplexity: None, ttt_step_time: 0.42598, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:48,650 | INFO | step: 26, accumulated_step: 416, loss: 0.51759, perplexity: None, ttt_step_time: 0.42560, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:49,076 | INFO | step: 27, accumulated_step: 432, loss: 0.50721, perplexity: None, ttt_step_time: 0.42486, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:49,501 | INFO | step: 28, accumulated_step: 448, loss: 0.48393, perplexity: None, ttt_step_time: 0.42548, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:49,929 | INFO | step: 29, accumulated_step: 464, loss: 0.50045, perplexity: None, ttt_step_time: 0.42712, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "2025-10-25 19:15:50,355 | INFO | step: 30, accumulated_step: 480, loss: 0.50168, perplexity: None, ttt_step_time: 0.42580, score_seq_time: 0.00000, eval_step_time: 0.00003\n",
      "torch.Size([480])\n"
     ]
    }
   ],
   "source": [
    "seq = \"HRQALGERLYPRVQAMQPAFASKITGMLLELSPAQLLLLLASEDSLRARVDEAMELII\"\n",
    "\n",
    "# Load ESM-2 model and data\n",
    "model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval().to(device)  # disables dropout for deterministic results\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter([(None, seq)])\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "# ================ TTT ================\n",
    "ttt_cfg = DEFAULT_ESM2_35M_TTT_CFG\n",
    "model = ESM2TTT.ttt_from_pretrained(model, ttt_cfg)\n",
    "model.ttt(seq)\n",
    "# =====================================\n",
    "\n",
    "# Extract per-residue representations\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[12])\n",
    "token_representations = results[\"representations\"][12]\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "print(sequence_representations[0].shape)\n",
    "\n",
    "# Rest model to original state (after this model.ttt can be called again on another protein)\n",
    "# ================ TTT ================\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESMFold\n",
    "\n",
    "Adaptation of an official [ESMFold example](https://github.com/facebookresearch/esm) to use ProteinTTT before predicting protein structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-25 18:43:22,370 | INFO | step: 0, accumulated_step: 0, loss: None, perplexity: None, ttt_step_time: 0.00000, score_seq_time: 0.00000, eval_step_time: 2.49081, plddt: 38.43030\n",
      "2025-10-25 18:43:24,946 | INFO | step: 1, accumulated_step: 4, loss: 2.54688, perplexity: None, ttt_step_time: 0.54727, score_seq_time: 0.00000, eval_step_time: 2.02741, plddt: 36.79425\n",
      "2025-10-25 18:43:27,480 | INFO | step: 2, accumulated_step: 8, loss: 2.51953, perplexity: None, ttt_step_time: 0.51081, score_seq_time: 0.00000, eval_step_time: 2.02258, plddt: 38.01218\n",
      "2025-10-25 18:43:30,014 | INFO | step: 3, accumulated_step: 12, loss: 2.48633, perplexity: None, ttt_step_time: 0.51053, score_seq_time: 0.00000, eval_step_time: 2.02268, plddt: 35.67231\n",
      "2025-10-25 18:43:32,630 | INFO | step: 4, accumulated_step: 16, loss: 2.27734, perplexity: None, ttt_step_time: 0.51160, score_seq_time: 0.00000, eval_step_time: 2.02284, plddt: 76.67175\n",
      "2025-10-25 18:43:35,166 | INFO | step: 5, accumulated_step: 20, loss: 2.38867, perplexity: None, ttt_step_time: 0.51247, score_seq_time: 0.00000, eval_step_time: 2.02350, plddt: 46.32459\n",
      "2025-10-25 18:43:37,767 | INFO | step: 6, accumulated_step: 24, loss: 2.35938, perplexity: None, ttt_step_time: 0.51232, score_seq_time: 0.00000, eval_step_time: 2.02263, plddt: 79.08147\n",
      "2025-10-25 18:43:40,306 | INFO | step: 7, accumulated_step: 28, loss: 2.14062, perplexity: None, ttt_step_time: 0.51331, score_seq_time: 0.00000, eval_step_time: 2.02434, plddt: 77.67902\n",
      "2025-10-25 18:43:42,839 | INFO | step: 8, accumulated_step: 32, loss: 1.91309, perplexity: None, ttt_step_time: 0.51186, score_seq_time: 0.00000, eval_step_time: 2.02049, plddt: 77.56664\n",
      "2025-10-25 18:43:45,373 | INFO | step: 9, accumulated_step: 36, loss: 1.85156, perplexity: None, ttt_step_time: 0.51285, score_seq_time: 0.00000, eval_step_time: 2.02059, plddt: 46.61237\n",
      "2025-10-25 18:43:47,906 | INFO | step: 10, accumulated_step: 40, loss: 1.51270, perplexity: None, ttt_step_time: 0.51270, score_seq_time: 0.00000, eval_step_time: 2.02073, plddt: 43.76756\n",
      "79.08150074294205\n"
     ]
    }
   ],
   "source": [
    "model = esm.pretrained.esmfold_v1()\n",
    "model = model.eval().cuda()\n",
    "\n",
    "# Optionally, uncomment to set a chunk size for axial attention. This can help reduce memory.\n",
    "# Lower sizes will have lower memory requirements at the cost of increased speed.\n",
    "# model.set_chunk_size(128)\n",
    "\n",
    "sequence = \"GIHLGELGLLPSTVLAIGYFENLVNIICESLNMLPKLEVSGKEYKKFKFTIVIPKDLDANIKKRAKIYFKQKSLIEIEIPTSSRNYPIHIQFDENSTDDILHLYDMPTTIGGIDKAIEMFMRKGHIGKTDQQKLLEERELRNFKTTLENLIATDAFAKEMVEVIIEE\"\n",
    "\n",
    "# ================ TTT ================\n",
    "ttt_cfg = DEFAULT_ESMFOLD_TTT_CFG\n",
    "ttt_cfg.seed = 0  # Trying TTT with several different seeds may enable finding structure with higher pLDDT\n",
    "ttt_cfg.steps = 10\n",
    "model = ESMFoldTTT.ttt_from_pretrained(model, esmfold_config=model.cfg)\n",
    "df = model.ttt(sequence)\n",
    "# =====================================\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.infer_pdb(sequence)\n",
    "\n",
    "with open(\"result.pdb\", \"w\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "import biotite.structure.io as bsio\n",
    "struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
    "print(struct.b_factor.mean())  # this will be the pLDDT\n",
    "\n",
    "# Rest model to original state (after this model.ttt can be called again on another protein)\n",
    "# ================ TTT ================\n",
    "model.ttt_reset()\n",
    "# ====================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteinttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
